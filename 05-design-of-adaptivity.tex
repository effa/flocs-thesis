\chapter{Design of Adaptivity}
\label{chap:design-of-adaptivity}

\begin{itemize}
\item RoboMission = app for efficient and fun learning of elementary programming for children (= mission)
\item how: entertaining problems of optimal difficulty $\rightarrow$ max \emph{flow} $\rightarrow$ max fun, learning efficiency, happiness
\item covered concepts: sequences of commands, repeat, while, if, if-else, simple tests (comparing)
%\item linearized description: design (this chapter), implementation (next chapter); in reality: many iterations
\end{itemize}


\section{System Behavior}
\label{sec:robomission.behavior}

Wide range of task difficulty, together with the adaptive behavior,
should make the systems useful for anybody who wants to learn
elementary programming.
However, this long-term goal requires many iterations,
as well as a lot of data.
Currently, the system primarily targets at children between 8-15 years.

\subsection{Main Use Case}
\label{sec:robomission.use-case}

\begin{itemize}
\item Student visits the home page of the project, reads the "promotional slides" and tries the game with manual controls. On the last slide, they click on the recommended task from the 1st level.
(REF: img)
\item Student creates the program using Blockly blocks and can run the program as many times as needed. (REF: img) Program execution is visualized. Student can change the speed of the execution.
\item After each unsuccessful execution, a short message explaining why the task was not solved is shown (e.g. "The spaceship must reach the final row.") (REF: img)
\item Student is able to solve the first few tasks quickly (within 2 minutes).
\item After solving each task, student is shown a visualization of obtaining points (called credits) (REF: printscreen). After a few solved tasks, student progresses to next level.
\item After each solved task, student is shown a dialog with one recommended task, and also a link to the page with overview of all tasks (REF: img).
\item Student is able to solve any task recommended by the system (within 15 minutes).
\item Each new concept (e.g. block) is explained in the task where it appears for the first time. (REF: img), so the student understands all elements in the game world and blocks available in the toolbox.
\item Students with some prior programming skill should progress through first few levels quickly (within 10 minutes) and get to the more challenging tasks containing both types of loops, conditionals etc.
\item Student is not bored by neither too easy task requiring many commands (i.e. taking more than 1 minute to build the streightforward solution), nor by the sequence of either too easy or too similar tasks.
\item Student can sign up (or log in without registration through their social accounts) at any moment to save their progress. Even without singing up, the system can associate the student with its progress using session cookie (but also provides a button to clear the history).
\item Student can provide a feedback or report a bug easily (and the feedback is send to admins by an email).
\end{itemize}
(TBA: add diagram with images for all these steps linked by arrows showing transitions)

% TODO: consider some of the following notes
% - Design of tasks for the system is described in section \ref{sec:robomission.tasks}.
% - Adaptive aspect of the behavior is described in section \ref{sec:robomission.adaptability}.
%\item intuitive and simple user interface crucial (aiming at children, they need to focus on learning programming, it would be bad to waste their mental power on understanding a complex interface)
%\item mini-instructions (ref to the Google research on ignoring instructions, show how it was solved in Blockly Games; ref figure)
%\item mini-explations (difference from instructions: after the fact) (ref figure) (they also serve as a convenient mean to game resetting)
%\item motivation: intrinsic (fun challenging game + optimal difficulty) and simple external motivation scheme: credits and levels


\subsection{Four Modes of Usage}
\label{sec:robomission.use-cases}

In addition to the main use case described in the previous section,
which assumes a new student without any context (e.g. a classroom),
the system can be potentially used in other (or more specific) ways.

\begin{itemize}
\item "Hour of Code" mode
  \begin{itemize}
  \item single hour
  \item mainly as a motivation to programming
  \item using RoboBlocks
  \item directly at elemenatry and high schools, or at home
  \item plus: MjUNI workshop
  \item shorter promotianal version for DODs (?) ("10 minutes of code")
  \item (should be strictly time-limited; certificate at the end)
  \end{itemize}
\item "Foundations mode" individual learning of elementary programming (individual at home or in a classroom, from several days to several weeks, depending on the prior skill); natural continuation of the first "Hour of Code" (next levels, with RoboBlocks)
\item "University mode" -- levels with RoboCode/Python, at home / secondary schools, KSI (0th problem set), IB111 (0th/1st motivational lesson - needs Python and to be better than turtle)
\item "Competition mode" -- competitions such as Purkiada, Pevnost FI, KSI (advanced problem sets), new FIBot (physical version already in InterSoB 2017); this also includes testing mode for RH interns
\end{itemize}

All these modes can be naturally implemented as distinct levels,
going from the easy tasks using RoboBlocks for "Hour of Code",
gradually transitioning to the RoboCode during learning the "Foundations",
using full-fledged Python for "University mode"
and offering both blocks and Python for the individual competitions.
Levels from the past compettions can be made public for all students.


\section{Domain Model}

\begin{itemize}
\item tasks divided into hierarchical PS (2 layers): called missions and phases
\item missions -- ordered, 9?, TODO: example/all?,
\item phases of a mission -- ordered, about 3?, TODO: example,
\item tasks within phase -- unordered, interchangeable, about 5?
\item TODO: link to what presented in earlier chapters
\item FIG
\end{itemize}


\section{Student Model}

\begin{itemize}
\item skill for each chunk (PS) (or rather "verified skill"), between 0 and 1
\item update: phase skill $s^0_f \leftarrow 0$;
  $s^{t+1}_f \leftarrow \min(1, s^t_f + \max(p, \frac{1}{|F_f|}))$
  (TODO: explain + notation: f, p, F)
\item update: mission skill: just average of phase skills (huge simplification...)
\item TODO: link to what presented in earlier chapters
\item TODO: discretized performance (elaborate: values, how computed, REF)
\end{itemize}


\section{Tutor Model}

\begin{itemize}
\item PS selection: first unmastered
  (first unmastered phase of first numastered mission)
  (reasoning: students want "green everything", small number of PS)
\item task selection: random + filter to avoid solved tasks
  (reasoning: interchangeable tasks; exploration maximization)
\item mastery decision: student model above + threshold exactly 1 (?)
\item TODO: link to what presented in earlier chapters
\end{itemize}


% TODO: Move/remove the following figures:
\imgW{robomission-levels-credits}{Students earn credits after each solved task.}
\imgW{robomission-tasks-overview}{Overview of all tasks. There is currently 9 levels, each containing about 8 tasks.}


\section{Monitoring and Analysis}
\label{sec:robomission.monitoring}

Even with careful testing, there will always be some errors in the deployed systems.
For example, there might be a task that is much easier than expected,
due to missing limit or some other mistake in its setting.
In addition to the errors in data,  % TODO: fix parallelism
the adpative behavior of the system is extremelly difficult to test as well.
As discused in section \ref{sec:metrics-and-evaluation} is only a proxy for our true objectives
and can be sometimes misleading.
As a result, it is not even more practical, but even neccessary to deploy system
that is imperfect, and then find and fix the problems that arise.
To spot the problems as soon as possible,
monitoring is a crucial component,
that facilites iterative improvement of the system.
% TODO: ref to iterative improvement section / rule of the loop principle

\subsection{Admin Requirements}
\label{sec:admin-requirements}

Similarly to regular users, administrators also have requirements on the systems:

\begin{itemize}
\item Admin can immediately see how much is the system used and how the system behaves with respect to the short-term ("live-evaluation") metrics (...)
\item Admin receives feedback from provided by users, and error reports on unhandled exceptions.
\item Admin can see metrics on individual tasks (to quickly detect issues with a task).
\end{itemize}


\subsection{Monitoring Components}

To fulfill the requiremetns from section \ref{sec:admin-requirements},
the system includes the following components:

\begin{itemize}
\item \textbf{Google Analytics} --
  shows distribution of users with respect to time and space.
  In addition to page visits,
  it can also process specific events sent from the frontend,
  such as clicking on the execution button,
  and divide them into groups, e.g. by task or group for AB experiment.
  (figure \ref{fig:google-analytics})
\item \textbf{Monitoring Dashboard} (see figure \ref{fig:monitoring-dashboard})
      which shows values of metrics for last month.
      (Computed metrics are described in section \label{sec:robomission.metrics}.)
\item \textbf{User Feedback} --
  a modal form that can be opened by a user on any page
  to send us a message that something is not working as expected.
  Each user feedback is send to the administrators by an email.
\item \textbf{Error Reports} --
  if an unhandled top-level error occur on the server,
  it is not only logged, but also send to the administrators.
\item \textbf{Data Exports} --
  All collected data are every week exported as a zip bundle containing
  CSV files prepared for convenient offline analysis.
\item \textbf{Investigaion Notebook} --
  a template of jupyter notebook with a command that generates exports
  and serves them directly as pandas data frames
  (see figure \ref{fig:investigation-notebook}).
\item \textbf{Logs} --
  all requests, performed actions, unhandled errors and submitted feedback are logged
  to files on the server for manual inspection.
\end{itemize}


\imgW[0.7]{google-analytics}{Preview from Google Analytics (breakdown for "execution" event).}

% TODO: latest dashboard, ideally with readable values
\imgW[0.6]{monitoring-dashboard}{Metrics visualized in the monitoring dashobard.}

% TODO: update investigation notebook (fix error in last cell, current data;
% should show something interesting, or at least some descriptive analylis)
\imgW[0.7]{investigation-notebook}{Template of jupyter notebook for investigation of live data.}


\subsection{Metrics}
\label{sec:robomission.metrics}

% TODO: include live metrics if there are any
Every night, the system recomputes metrics related to the long-term objectives
(as described in \ref{sec:long-term-objectives}):

\begin{itemize}
\item "daily active students" = number of users who solved at least 1 task this day,
\item "solving hours" = total time spent on successful attempts,
\item "success ratio" = proportion of successful attempts,
\item number of solved tasks.
%\item (TBA: update if it changed)
\end{itemize}


The system also computes metrics about each task (in order to e.g. detect problematic ones):
\begin{itemize}
\item solved count,
\item median time,
\item success ratio.
\end{itemize}




% TODO: consider if to include non-functional requirements or not
%\section{Non-functional Requirements}
%\label{sec:robomission.nonfunctional-requirements}
%
%\begin{itemize}
%\item easy to understand code, pleasure to read and write (extend)
%\item easy to refactor and add new things (new tasks, levels, recommendation strategies etc.)
%\item robust, efficient, interpretable behavior
%\end{itemize}


\section{Rule of the Loop}
\label{sec:robomission.rule-of-the-loop}

\begin{itemize}
\item the design interleaved with the implementation -> final design is completely different than the original one
\item ref: rule of the loop (ref: in game desing: Book of Lenses, for ML: Google Rules of ML, for WS development: SCRUM; our project includes all these 3 elements)
\item first prototype: 2016, one year of development, thrown away; for testing our initial ideas and find what works and what not; 50 tasks with a robot in maze
  \begin{itemize}
  \item problems with the robot in the maze: not fun (boring, not inovative, repetitiveness), did not allow for a plenty of diverse easy tasks (which is necessary for adaptive systems), required a lot of blocks even for simple programs (compared to the SpaceGame)
  \item problems with the codebase (maintainability, extensibility - why?)
  \item and the good things? (SPA, explored/verified useful technologies, such as Blockly and Django)
  \end{itemize}
\end{itemize}

\imgW{prototype-task-environment}{First prototype of the system, with a classic robot-in-maze game.}
