NOTE: hidden variables (hidden state) (knowledge and skills, possibly also affect, motivation)
vs. observable variables (correctness, solving time, time series of program snapshots)


TODO: \cite{student-models-review-2012}:
(for inner loop: cognitive tutors and constraint based models)
- cognitive tutors - skills as rules,
  mastered skill: rule correctly applied (multiple-times),
  allows for modeling misconceptions ("MISconcepts") (incorrect rules)
    -> useful for automatic hint generation ("just-in-time feedback"),
  example: the Lisp Tutor
- (and contstraint based modeling - skills as predicates)
- doesn't require long-term student model, can be just for the current topic;
  however, the transfer of skill estimates between topics can help,
  because 1 skill is often required in multiple topic
  - this is known as (\emph{transfer model} or) \emph{knowledge tracing}
  (and I think that it is the same thing which we call "prior knowledge estimation")
  (but in our context, \emph{skill tracing} would be better name)


\subsection{Item Response Theory}
\label{sec:irt}


NOTE: additional parameters: discrimination (how much is the performance sensitive to the skill), pseudo-guessing (the minimum probability of success, useful mainly for multple-choice questions, probably not very useful for us)

This basic model was originally developed for a simple knowledge testing
  and therefore it assumes a single constant skill.
However, programming skill is multidimensional;
  for example, one student can be proficient with functions and struggle with loops,
  while another student can master loops and struggle with functions.
Furthermore, these skills should be ideally changing significantly during
  the interaction with the system, because students are learning.

NOTE: multidimension extension: x = skill vector * discrimination vector - task bias
(this is basically what we tried in the first prototype, with fixed discrimination vector,
although we formulated it in the online "ELO" variant)
(REF?:The difficulty of test items that measure more than one ability.,
Using multidimensional item response theory to understand what items and tests are measuring.)

Another drawback of the IRT is that it only uses
  the binary data about successes and failures.
As nearly all interactions in programming learning systems end with a solved task,
  it would be more useful to work with solving times,
  which can provide more information about students' skills.

Item response theory can be extended to overcome these limitations.
\emph{Problem Response Theory} (PRT)
\cite{alg.problem-response-theory, pelanek-student-modeling-times}
% TODO: only cite the more relevant paper (or extend this section and cite both
% on relevant places)
predicts problem solving times instead of probability of success,
assuming an exponential relationship between a problem solving skill
and the time to solve a problem.
PRT can be formulated to use multidimensional skills.
The model parameters (skills and difficulties) can can be estimated from the data
  using one of the \emph{maximum likelihood estimation} algorithms.
  % TODO: cite paper describing the parameters estimation (or MLE?)
% (for IRT, it's \cite{irt-theory-and-practice}, but PRT would be better)

- underlying domain model:
  - single concept / flat concepts -> classical IRT
  - Q-matrix -> multidimensional version (see thran-thesis)
  - hierachical structure of concepts ? (see Millán and Pérez-de-la-Cruz (2002))

% TODO: find and provide the details about the learning extension of PRT
% (isn't it already the elo?)

% TODO: Add note that the assumption of exponential relationship is justified
% by observed solving solving times distribution and it is also intuitively
  % plausible - multiplicative nature of solving times.

NOTE: Main problem - without learning; in principle can recompute parameters after
each interaction, but that is not feasible in online learning systems; remedy: PFA (student-related parameters can be computed online,), Elo models (both student and task-related parameters can are computed online)

NOTE: IRT is a speical case of Naive Bayes, which is itself a special case of BN model:
  - Naive Bayes = all task performances are independent given the hidden latent skill
  - furthermore, the conditional probabilities P(performance on task t | skill
  theta) cannot be arbitratry, they must have a logistic distribution

NOTE: modeling response times (nice summary in thran-thesis)
- log-time from normaln distribution with mean d - a * theta (and variance c),
  ie. assumption is exponential relationship between the solving time and the skill?
  (this statement is not clear, because it depend on what you denote as skill,
  e.g. if you say that skill is exp(theta), than the relationship is linear...)
- incorporating multidimensionnal skills (flat concepts model): d, a vectors; update skill of each concpet contained in the task


NOTE: PFA - logistic model with learning (logistic fn, set of skills for each concept, initial skills, constant incread after a correct answer; total skill = sum of skills of concepts contained in the task, squashed byt the logistic fn)
REF: Pavlik 2009: Performance factors analysis—a new alternative to knowledge tracing.

NOTE: PFAE - combines Elo with PFA (make the PFA online for both student and task parameters)
(basic version: no domain, repeated answers to single item -> prior knowledge + current knowledge,
not sure how much relevant for us)
